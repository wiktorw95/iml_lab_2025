#  Wniosek z Por贸wnania Autoenkoder贸w (CAE vs. FAE)

##  Cel Eksperymentu

Celem eksperymentu bya analiza i por贸wnanie wydajnoci dw贸ch r贸偶nych architektur autoenkoder贸w na zbiorze danych **Fashion MNIST** z zastosowaniem warstwy **Augmentacji (Obr贸t)**:

1.  **Autoenkoder Konwolucyjny (CAE):** Wykorzystujcy warstwy `Conv2D` i `Conv2DTranspose`.
2.  **Autoenkoder Oparty na Gstych Warstwach (FAE):** Wykorzystujcy jedynie warstwy `Dense` (w peni poczone).

Oba modele zostay wytrenowane przez **10 epok** z t sam strat **Mean Squared Error (MSE)**, aby oceni ich zdolno do rekonstrukcji obraz贸w.

##  Analiza Wynik贸w Treningu

| Model | Ostatnia Strata Walidacyjna (val_loss) | Czas Treningu na Epok | Liczba Parametr贸w (Szacunkowa) |
| :--- | :--- | :--- | :--- |
| **Autoenkoder Konwolucyjny (CAE)** | **0.0221** | $\approx 13-14 \text{ s}$ | Mniejsza (dziki udostpnianiu wag) |
| **Autoenkoder Gsty (FAE)** | **0.0089** | $\approx 2 \text{ s}$ | Wiksza (Dense(784) ma du偶o wag) |

---

### 1. Wydajno Strata (Loss)

* **Zwyky Autoenkoder Gsty (FAE)** osign znacznie **ni偶sz strat walidacyjn (0.0089)** w por贸wnaniu do Autoenkodera Konwolucyjnego (0.0221).
* **Wniosek dotyczcy straty:** Ni偶sza strata FAE sugeruje, 偶e by on bardziej efektywny w bezporednim odwzorowaniu ka偶dego wejciowego piksela na piksel wyjciowy, co jest typowe dla FAE, gdy celem jest **dokadna rekonstrukcja pikseli**. Jednak ta ni偶sza strata nie musi oznacza lepszej **jakoci wizualnej** rekonstrukcji, zwaszcza w zadaniach redukcji szum贸w lub uczenia si reprezentacji semantycznej.

### 2. Efektywno Czasowa

* **Autoenkoder Gsty (FAE)** trenowa **znacznie szybciej** ($\approx 2 \text{ s}$ na epok) ni偶 Autoenkoder Konwolucyjny ($\approx 13 \text{ s}$ na epok).
* **Wniosek dotyczcy czasu:** FAE wymaga znacznie mniej zasob贸w obliczeniowych na pojedyncz epok, poniewa偶 nie wykonuje kosztownych obliczeniowo operacji splotowych.

##  Podsumowanie

| Autoenkoder | Zalety | Wady | Optymalny dla |
| :--- | :--- | :--- | :--- |
| **Konwolucyjny (CAE)** | Uczy si **cech przestrzennych**, generuje **ostrzejsze** rekonstrukcje, lepszy w redukcji szum贸w (invariance). | Du偶szy czas treningu, wy偶sza strata MSE w tym tecie. | Ekstrakcja cech, Zadania Generatywne, Ograniczenia Danych. |
| **Gsty (FAE)** | Bardzo **szybki trening**, najni偶sza strata MSE. | Ignoruje struktur przestrzenn, rekonstrukcje mog by **rozmyte** lub mniej semantycznie poprawne. | Bardzo proste zestawy danych, **Szybka kompresja/dekompresja** danych wektorowych. |
