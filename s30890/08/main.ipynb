{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "EPOCHS = 10\n",
    "BATCH = 64\n",
    "LR = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    \"mnist\",\n",
    "    split=[\"train\", \"test\"],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")\n",
    "\n",
    "def normalize_img(image, label):\n",
    "    return tf.cast(image, tf.float32) / 255.0, label\n",
    "\n",
    "ds_train_norm = ds_train.map(normalize_img).cache().shuffle(1000).batch(BATCH).prefetch(tf.data.AUTOTUNE)\n",
    "ds_test_norm  = ds_test.map(normalize_img).batch(BATCH).prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataset, name=\"model\"):\n",
    "    loss, acc = model.evaluate(dataset, verbose=0)\n",
    "    print(f\"{name}: loss={loss:.4f}, accuracy={acc:.4f}\")\n",
    "    return loss, acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xyz/Main/IML/iml_lab_2025/s30890/08/.venv/lib/python3.11/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 93/938\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6229 - loss: 1.2925"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 23:10:55.531929: I tensorflow/core/kernels/data/tf_record_dataset_op.cc:396] The default buffer size is 262144, which is overridden by the user specified `buffer_size` of 8388608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9153 - loss: 0.3025 - val_accuracy: 0.9425 - val_loss: 0.1932\n",
      "Epoch 2/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9600 - loss: 0.1377 - val_accuracy: 0.9666 - val_loss: 0.1135\n",
      "Epoch 3/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9723 - loss: 0.0943 - val_accuracy: 0.9684 - val_loss: 0.1017\n",
      "Epoch 4/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9785 - loss: 0.0721 - val_accuracy: 0.9737 - val_loss: 0.0891\n",
      "Epoch 5/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9830 - loss: 0.0570 - val_accuracy: 0.9729 - val_loss: 0.0878\n",
      "Epoch 6/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9867 - loss: 0.0466 - val_accuracy: 0.9755 - val_loss: 0.0786\n",
      "Epoch 7/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9889 - loss: 0.0377 - val_accuracy: 0.9766 - val_loss: 0.0770\n",
      "Epoch 8/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9917 - loss: 0.0303 - val_accuracy: 0.9777 - val_loss: 0.0751\n",
      "Epoch 9/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9936 - loss: 0.0242 - val_accuracy: 0.9770 - val_loss: 0.0760\n",
      "Epoch 10/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9945 - loss: 0.0202 - val_accuracy: 0.9768 - val_loss: 0.0810\n",
      "baseline (test): loss=0.0810, accuracy=0.9768\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.08101446181535721, 0.9768000245094299)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_baseline_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(LR),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "baseline = build_baseline_model()\n",
    "baseline.fit(ds_train_norm, epochs=EPOCHS, validation_data=ds_test_norm)\n",
    "\n",
    "evaluate_model(baseline, ds_test_norm, \"baseline (test)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomRotation(0.15),\n",
    "    tf.keras.layers.RandomTranslation(0.1, 0.1),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 23:11:24.422348: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for images, labels in ds_train_norm.take(1):\n",
    "    for i in range(3):\n",
    "        aug_img = data_augmentation(images)[i]\n",
    "        plt.imshow(aug_img.numpy().squeeze(), cmap='gray')\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline (augmented test): loss=18.5535, accuracy=0.2351\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(18.553516387939453, 0.23510000109672546)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def augment_for_test(image, label):\n",
    "    # negatyw (30%)\n",
    "    if tf.random.uniform(()) < 0.3:\n",
    "        image = 1.0 - image\n",
    "\n",
    "    # losowy obrót 0/90/180/270\n",
    "    k = tf.random.uniform((), minval=0, maxval=4, dtype=tf.int32)\n",
    "    image = tf.image.rot90(image, k)\n",
    "\n",
    "    # losowe przesunięcie (pad + crop)\n",
    "    dx = tf.random.uniform((), -3, 3, dtype=tf.int32)\n",
    "    dy = tf.random.uniform((), -3, 3, dtype=tf.int32)\n",
    "\n",
    "    # powiększamy do 34x34\n",
    "    image = tf.image.pad_to_bounding_box(image, 3, 3, 34, 34)\n",
    "\n",
    "    # przywracamy 28x28 z przesunięciem\n",
    "    image = tf.image.crop_to_bounding_box(image, 3 + dy, 3 + dx, 28, 28)\n",
    "\n",
    "    return image, label\n",
    "\n",
    "ds_test_aug = ds_test.map(normalize_img).map(augment_for_test).batch(BATCH)\n",
    "evaluate_model(baseline, ds_test_aug, \"baseline (augmented test)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xyz/Main/IML/iml_lab_2025/s30890/08/.venv/lib/python3.11/site-packages/keras/src/layers/preprocessing/data_layer.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7132 - loss: 0.9263\n",
      "Epoch 2/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8543 - loss: 0.4869\n",
      "Epoch 3/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8794 - loss: 0.4007\n",
      "Epoch 4/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8899 - loss: 0.3664\n",
      "Epoch 5/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8983 - loss: 0.3379\n",
      "Epoch 6/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9035 - loss: 0.3226\n",
      "Epoch 7/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9081 - loss: 0.3024\n",
      "Epoch 8/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9125 - loss: 0.2901\n",
      "Epoch 9/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9135 - loss: 0.2819\n",
      "Epoch 10/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9170 - loss: 0.2745\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x11e290550>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_baseline_model_aug():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Rescaling(1.0, input_shape=(28, 28, 1)), # dane już są 0–1\n",
    "        data_augmentation,   # augmentacja tylko w treningu\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(LR),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "baseline_aug = build_baseline_model_aug()\n",
    "baseline_aug.fit(ds_train_norm, epochs=EPOCHS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline_aug (test): loss=0.1508, accuracy=0.9542\n",
      "baseline_aug (aug test): loss=10.2699, accuracy=0.3748\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10.269867897033691, 0.3747999966144562)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(baseline_aug, ds_test_norm, \"baseline_aug (test)\")\n",
    "evaluate_model(baseline_aug, ds_test_aug, \"baseline_aug (aug test)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.8324 - loss: 0.5224 - val_accuracy: 0.9582 - val_loss: 0.1299\n",
      "Epoch 2/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.9390 - loss: 0.1995 - val_accuracy: 0.9638 - val_loss: 0.1151\n",
      "Epoch 3/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.9553 - loss: 0.1459 - val_accuracy: 0.9753 - val_loss: 0.0815\n",
      "Epoch 4/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.9615 - loss: 0.1218 - val_accuracy: 0.9816 - val_loss: 0.0592\n",
      "Epoch 5/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9668 - loss: 0.1075 - val_accuracy: 0.9756 - val_loss: 0.0711\n",
      "Epoch 6/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9706 - loss: 0.0965 - val_accuracy: 0.9805 - val_loss: 0.0669\n",
      "Epoch 7/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.9737 - loss: 0.0855 - val_accuracy: 0.9822 - val_loss: 0.0573\n",
      "Epoch 8/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.9752 - loss: 0.0818 - val_accuracy: 0.9851 - val_loss: 0.0495\n",
      "Epoch 9/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9766 - loss: 0.0758 - val_accuracy: 0.9850 - val_loss: 0.0498\n",
      "Epoch 10/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.9779 - loss: 0.0718 - val_accuracy: 0.9852 - val_loss: 0.0470\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x11e2148d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_conv_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Rescaling(1.0, input_shape=(28, 28, 1)),\n",
    "        data_augmentation,\n",
    "        tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(),\n",
    "        tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(10, activation='softmax'),\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(LR),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "conv_model = build_conv_model()\n",
    "conv_model.fit(ds_train_norm, epochs=EPOCHS, validation_data=ds_test_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN (test): loss=0.0470, accuracy=0.9852\n",
      "CNN (aug test): loss=4.6350, accuracy=0.4641\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4.634981632232666, 0.4641000032424927)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(conv_model, ds_test_norm, \"CNN (test)\")\n",
    "evaluate_model(conv_model, ds_test_aug, \"CNN (aug test)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
