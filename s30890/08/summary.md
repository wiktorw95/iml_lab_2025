Modele Dense uczone na czystym MNIST działały dobrze na danych standardowych, ale kompletnie zawodziły na danych z zakłóceniami (accuracy ~0.09), ponieważ nauczyły się sztywnych wzorców zależnych od położenia pikseli. Dodanie augmentacji podczas treningu poprawiło ich odporność (do ~0.37), co pokazuje, że wzbogacenie danych pomaga, jednak sama architektura Dense nadal ogranicza możliwości generalizacji. Najlepsze wyniki uzyskał model konwolucyjny (CNN), który dzięki filtrom przestrzennym naturalnie radzi sobie z przesunięciami i obrotami — osiągnął najwyższą dokładność na danych normalnych (0.985) oraz największą odporność na dane zaugmentowane (~0.46). Ostatecznie największy wpływ miała zmiana architektury na CNN, a augmentacja dodatkowo poprawiała odporność modeli na zniekształcenia.